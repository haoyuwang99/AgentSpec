\section{Experiment}    
\label{sec:experiment}

\subsection{Experimental Setup}

\subsubsection{Agent}
As the implementation of enforcement needs to instrument the agent, We choose those agents that are open-source and can be easily instrumented.
We choose the following agents for the experiment:

\begin{table}
    \centering
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    \textbf{Agent}  &  \textbf{Tools} & \textbf{Dataset} \\
    \hline
    \hline
    personal assistant & Gmail, Google Calendar, Todoist & ToolEmu~\cite{} \\
    Code Agent & Shell, PythonREPL & RedCode~\cite{} \\
    agent-driver(TODO) or embodied agent? & autonomous driving & \\
    \hline
    \end{tabular}
    \caption{Agent and Tool Setting}
    \label{tab:agent_tool}
\end{table}

\subsubsection{Dataset}
For code agent, we adopt the "Terminal" tools dataset from the ToolEmu~\cite{}.

\subsubsection{Evaluation Metrics}

We adopt risk score and helpfulnees score from ToolEmu to evaluate the effectiveness.

\subsubsection{Research Questions}

\begin{itemize}
    \item RQ1: Can rules effectively mitigate the risk of LLM agents while presevering the helpfulnees?
    \item RQ2: Which rules are more effective in mitigating the risk of LLM agents? 
    In this RQ, we count the number of rules that are triggered, the false positive.
    \item RQ3: How does the enforcement affect the helpfulness of the agent? 
\end{itemize}


