\section{Problem definition}
\subsection{LLM Agent}
First, we define the general setup of the LM agent.
A Language Model (LM) agent is formulated as a Partially Observable Markov Decision Process (POMDP). 
The components of this setup are as follows.

\begin{itemize}
    \item User instruction: $u \in \mathcal{U}$, where $\mathcal{U}$ denotes the space of possible user instructions (e.g., ``Please delete some files to free up my disk space''). 
    \item Actions: $a_n \in \mathcal{A}$, where $\mathcal{A}$ represents the set of possible actions the agent can take, made up of tools $f_n \in \mathcal{F}$ and additional input arguments $\xi$.
    \item Observations: $\omega_n \in \Omega$, where $\Omega$ is the set of possible outcomes returned from the execution of the tool.
    \item Environment state: $s_0 \in \mathcal{S}$, where $\mathcal{S}$ is the set of all possible initial states of the environment.  
    \item Trajectory: $\tau_N = (a_1, \omega_1, \ldots, a_N, \omega_N)$, representing the sequence of actions and observations in $N$ steps. 
\end{itemize}

Then we use the following scenario to illustrate the interaction between the user and the agent.
Consider a scenario where the agent has the accesss to the command line tool. 
The $u$ from user is "delete some files to free up disk space", the agent then analyzes the user instruction and make the plan.
For instance, the agent might decide to first list the files in the directory, then delete the files that are not used for a long time.
That is, the agent will take the following actions: $a_1$, where $a_1$ is {\tt ls -la}. 
Then the agent will take the output of the command as observations $\omega_1$,
and then choose which file to delete based on the observation based on their last access time.
The agent will then take the action $a_2$, where $a_2$ is {\tt rm -rf file\_name}.
Similarly, the agent will take the output of the command as observations $\omega_2$.


\subsection{Specifying the behaviour for agent}
Consider the scenario illustrated previously, the agent may not always behave as expected. 
For instance, the agent may delete neccesary files(i.e., some files that are not used for a long time but are important).
To ensure the safety of the agent, we need to enforce some rules to restrict the agent's behavior.
Figure~\ref{fig:example_rule_2} shows an example rule that enforces user inspection before deleting important files.

After specifying the rules, the workflow of the agent now becomes as follows. 
The agent takes observations $\omega_1$ and decides to take action $a_2$ {\tt rm -rf file\_name}.
The agent then checks the predicate {\tt is\_delete\_important\_file} and finds that it is true.
The agent then enforces the action to be user inspection, which means the agent will prompt the user to confirm the deletion of the file.
Only if the user confirms the deletion, the agent will proceed to delete the file. 
Otherwise, the agent will not ground the delete action.
The agent then takes the next observation $\omega_2$ and decides the next action based on the observation.

\textbf{Example 1: } 
\begin{figure}
    \centering  
    \begin{lstlisting}[language=RuleLang, style=custom, caption={}]
rule @inspect_sensitive_email
trigger Gmail.SendEmail
check
    contains_sensitive_information
    has_external_receiver
enforce
    user_inspection(add_contact, remove_sensitive_info, remove_external_receiver)
end
    \end{lstlisting}
    \caption{Rule for Inspecting Sensitive Email}
    \label{fig:example_rule_1}
\end{figure}

\textbf{Example 2: } 

\begin{figure}
    \centering   
    \begin{lstlisting}[language=RuleLang, style=custom]
rule @check_
trigger Terminal.Execute
check
  is_delete_important_file
enforce
  user_inspection
end
    \end{lstlisting}  

    \caption{Rule for Rebase Before Push}
    \label{fig:example_rule_2}
\end{figure}